{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.12.0\n",
    "!pip install transformers==4.6.0\n",
    "!pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yfinance scikit-learn pandas numpy transformers tensorflow speechrecognition nltk langdetect pyaudio sentencepiece torch streamlit streamlit-webrtc gtts spacy langchain openai playsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations:<br>\n",
    "The Power of Generative AI: A Review of Requirements, Models, Input–Output Formats, Evaluation Metrics, and Challenges by Ajay Bandi, Pydi Venkata Satya Ramesh Adapa and Yudu Eswar Vinay Pratap Kumar Kuchi<br>\n",
    " \n",
    "2106.12985v2 Stock Market Analysis with Text Data: A Review Kamaladdin Fataliyev, Aneesh Chivukula, Mukesh Prasad, Wei Liu<br>\n",
    " \n",
    "Stock market prediction using artificial intelligence: A systematic review of systematic reviews Chin Yang Lin, João Alexandre Lobo Marques<br>\n",
    " \n",
    "A Study Analyzing an Innovative Approach to Sentiment Analysis with VADER by Chadha, Raman and Chaudhary, Aryan, Journal of Engineering Design and Analysis<br>\n",
    "\n",
    "Medium : A Beginner’s Guide to using AI in Stock Prediction with Google Colab and Tableau\n",
    "https://medium.com/@larry.deee/a-beginners-guide-to-using-ai-in-stock-prediction-with-google-colab-and-tableau-5e63153d3371\n",
    "\n",
    "Medium : Using Sentiment Analysis to Predict the Stock Market\n",
    "https://medium.com/analytics-vidhya/using-sentiment-analysis-to-predict-the-stock-market-77100295d753#:~:text=Using%20Sentiment%20Analysis%20to%20Predict%20the%20Stock%20Market,score%20index%20against%20the%20daily%20close%20return%20\n",
    "\n",
    "Medium : Ultimate Guide to Getting Started with LangChain\n",
    "https://medium.com/@zilliz_learn/ultimate-guide-to-getting-started-with-langchain-b9a87cb340f8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stock Related functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation Steps<br>\n",
    "Step 1: Firstly, we must install the necessary packages via pip and configure the required api keys<br>\n",
    "Step 2: Then load the required models from spacy and Vader to handle the NLP tasks and sentiment analysis tasks. <br>\n",
    "Step 3: Define Functions to load the ticker data from excel and the stock data from api <br>\n",
    "step 4: Setup Langchain and integrate with the transformer model and suitable prompt template to generate the summary <br>\n",
    "Step 4: We define a function for speech recognition to get the input from the user and convert it to text. <br>\n",
    "Step 5: Simultaneously fetch the entities from the voice input and hit the apis to get sufficient amount of data related to news articles as well as financial data to be ready for further text processing.<br>\n",
    "Step 6: Once we receive data from the api, we will do the sentimental analysis and generate a compound sentimental value.<br>\n",
    "Step 7: We do input the historical data of the stock and the sentimental analysis from Vader to the langchain where it will be having suitable prompt templates and language model to summarize about the recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy: It is a fundamental package for scientific computing with Python. It provides support for arrays, matrices, and a large collection of mathematical functions to operate on these data structures.<br>\n",
    "Spacy: An open-source library for advanced Natural Language Processing (NLP) in Python. It’s designed specifically for production use and helps in extracting entities and understanding text.<br>\n",
    "Vader: A lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.<br>\n",
    "News API: A simple HTTP REST API for searching and retrieving live articles from all over the web. It can be used to get news data based on keywords, sources, and other parameters.<br>\n",
    "Alpha Vantage API: Provides real-time and historical stock market data. This API can be used for financial analysis, market research, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\s567075\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import requests\n",
    "from langdetect import detect, LangDetectException\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import nltk\n",
    "import json\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "#     \"amazon\": \"AMZN\",\n",
    "#     \"apple\": \"AAPL\",\n",
    "#     \"google\": \"GOOGL\",\n",
    "#     \"microsoft\": \"MSFT\",\n",
    "#     \"facebook\": \"META\",\n",
    "#     \"tesla\": \"TSLA\",\n",
    "#     \"netflix\": \"NFLX\",\n",
    "#     \"paypal\": \"PYPL\",\n",
    "#     \"visa\": \"V\",\n",
    "#     \"salesforce\": \"CRM\"\n",
    "FINANCIAL_NEWS_SOURCES = [\n",
    "    \"bloomberg.com\",\n",
    "    \"cnbc.com\",\n",
    "    \"financialpost.com\",\n",
    "    \"financialexpress.com\",\n",
    "    \"marketwatch.com\",\n",
    "    \"reuters.com\",\n",
    "    \"wsj.com\",\n",
    "    \"yahoo.com\",\n",
    "]\n",
    "\n",
    "def fetch_historical_data(ticker, period='1mo'):\n",
    "    stock_data = yf.download(ticker, period=period)\n",
    "    return stock_data\n",
    "\n",
    "def fetch_realtime_data(ticker):\n",
    "    stock_data = yf.download(ticker, period='1d', interval='1m')\n",
    "    return stock_data\n",
    "\n",
    "def extract_companyName(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORG\":\n",
    "            return ent.text\n",
    "    return None\n",
    "\n",
    "def extract_ticker(companyName):\n",
    "        return company_tickers.get(companyName.lower(), None)\n",
    "\n",
    "def load_company_tickers(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    company_ticker_dict = pd.Series(df.ticker.values, index=df.company).to_dict()\n",
    "    return company_ticker_dict\n",
    "\n",
    "def extract_tickerFromExcel(companyName):\n",
    "    company_tickers = load_company_tickers('company-ticker.csv')\n",
    "    return company_tickers.get(companyName.lower(), None)\n",
    "\n",
    "# def predict_stock_price(history):\n",
    "#     predictor = pipeline('text-generation', model='distilgpt2')\n",
    "#     history_str = ' '.join([f\"{date}: {price}\" for date, price in history.items()])\n",
    "    \n",
    "#     prompt = f\"Predict the closing price for the next trading day based on the following history: {history_str}.\"\n",
    "#     max_input_length = predictor.model.config.n_positions - 20\n",
    "#     if len(prompt) > max_input_length:\n",
    "#         prompt = prompt[:max_input_length]\n",
    "#     prediction = predictor(prompt, max_new_tokens=20, num_return_sequences=1)\n",
    "#     predicted_price = float(re.findall(r\"\\d+\\.\\d+\", prediction[0]['generated_text'])[0])\n",
    "#     return predicted_price\n",
    "\n",
    "def fetch_news(company_name):\n",
    "    try:\n",
    "     with open('config.json') as config_file:\n",
    "      config = json.load(config_file)\n",
    "      api_key = config['newsAPI']\n",
    "    except:\n",
    "        print(\"Unable to access stock Data\")\n",
    "    query = f\"{company_name}\"\n",
    "    domains = ','.join(FINANCIAL_NEWS_SOURCES)\n",
    "    url = f\"https://newsapi.org/v2/everything?q={query}&domains={domains}&sortBy=publishedAt&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    print(url)\n",
    "    news_data = response.json()\n",
    "    if news_data[\"status\"] == \"ok\":\n",
    "        articles = news_data[\"articles\"]\n",
    "        return articles\n",
    "    else:\n",
    "        print(f\"Failed to fetch news: {news_data['message']}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_ticker_symbol_yahoo(common_name):\n",
    "    base_url = f\"https://query1.finance.yahoo.com/v1/finance/search?q={common_name}\"\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"Failed to fetch data: {response.status_code}\"\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except ValueError:\n",
    "        return \"Failed to parse JSON response\"\n",
    "\n",
    "    if 'quotes' in data and data['quotes']:\n",
    "        return data['quotes'][0]['symbol']\n",
    "    else:\n",
    "        return \"Ticker symbol not found\"\n",
    "    \n",
    "def get_ticker_symbol_yfinance(common_name):\n",
    "    try:\n",
    "        tickers = yf.Ticker(common_name)\n",
    "        info = tickers.info\n",
    "        \n",
    "        if 'symbol' in info:\n",
    "            return info['symbol']\n",
    "        else:\n",
    "            return \"Ticker symbol not found\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "    \n",
    "def get_ticker_symbol(common_name):\n",
    "    api_key = \"\"\n",
    "    base_url = \"https://finnhub.io/api/v1/search\"\n",
    "    params = {\n",
    "        'q': common_name,\n",
    "        'token': api_key\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    if data['count'] > 0:\n",
    "        for result in data['result']:\n",
    "            if common_name.lower() in result['description'].lower() and result['type'] == 'Common Stock':\n",
    "                print(result)\n",
    "                return result['symbol']\n",
    "        return \"Ticker symbol not found\"\n",
    "    else:\n",
    "        return \"Ticker symbol not found\"\n",
    "\n",
    "def fetch_daily_stock_data(symbol):\n",
    "    try:\n",
    "     with open('config.json') as config_file:\n",
    "      config = json.load(config_file)\n",
    "      api_key = config['alphavantage']\n",
    "    except:\n",
    "        print(\"Unable to access stock data\")\n",
    "\n",
    "\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}&outputsize=compact'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if \"Time Series (Daily)\" in data:\n",
    "        time_series = data[\"Time Series (Daily)\"]\n",
    "        stockData = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "        stockData = stockData.rename(columns={\n",
    "            \"1. open\": \"Open\",\n",
    "            \"2. high\": \"High\",\n",
    "            \"3. low\": \"Low\",\n",
    "            \"4. close\": \"Close\",\n",
    "            \"5. volume\": \"Volume\"\n",
    "        })\n",
    "        stockData.index = pd.to_datetime(stockData.index)\n",
    "        stockData = stockData.sort_index()\n",
    "\n",
    "        return stockData\n",
    "    else:\n",
    "        print(\"Error fetching data:\", data)\n",
    "        return None\n",
    "    \n",
    "def analyze_sentiment(articles):\n",
    "    try:\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "    except LookupError:\n",
    "        nltk.download('vader_lexicon')\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        \n",
    "    sentiments = []\n",
    "    for article in articles:\n",
    "        title = article.get('title') or ''\n",
    "        description = article.get('description') or '' \n",
    "        if title or description: \n",
    "            combined_text = title + ' ' + description\n",
    "            try:\n",
    "                if detect(combined_text) == 'en': \n",
    "                    sentiments.append(sia.polarity_scores(combined_text))\n",
    "            except LangDetectException:\n",
    "                continue  \n",
    "    if not sentiments: \n",
    "        return {'neg': 0, 'neu': 1, 'pos': 0, 'compound': 0}\n",
    "    \n",
    "    avg_sentiment = {\n",
    "        'negative': np.mean([s['neg'] for s in sentiments]),\n",
    "        'neutral': np.mean([s['neu'] for s in sentiments]),\n",
    "        'positive': np.mean([s['pos'] for s in sentiments]),\n",
    "        'average': np.mean([s['compound'] for s in sentiments])\n",
    "    }\n",
    "    return avg_sentiment\n",
    "\n",
    "def predict_stock_movement(sentiment):\n",
    "    if sentiment['average'] > 0.05:\n",
    "        return \"Invest\"\n",
    "    elif sentiment['average'] < 0:\n",
    "        return \"Do not invest\"\n",
    "    else:\n",
    "        return \"Hold\"\n",
    "    \n",
    "def decide_investment(predicted_price, current_price):\n",
    "    if predicted_price > current_price:\n",
    "        return \"Invest\"\n",
    "    else:\n",
    "        return \"Do not invest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer model related functions<br>\n",
    "Transformers: Provided by Hugging Face, this library is used for state-of-the-art NLP. It allows you to use pre-trained models for tasks like text summarization, translation, and more.<br>\n",
    "LangChain: This framework helps manage interactions with large language models, handling prompt templates and chaining multiple model calls.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from transformers import pipeline, TextGenerationPipeline\n",
    "import os\n",
    "import json\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "class CustomTextGenerationPipeline(TextGenerationPipeline):\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        kwargs['max_new_tokens'] = kwargs.get('max_new_tokens', 100)\n",
    "        kwargs['temperature'] = kwargs.get('temperature', 0.5)\n",
    "        return super().__call__(*args, **kwargs)\n",
    "\n",
    "custom_generator = CustomTextGenerationPipeline(\n",
    "    model=generator.model,\n",
    "    tokenizer=generator.tokenizer,\n",
    "    framework=generator.framework,\n",
    "    task=generator.task,\n",
    "    device=generator.device\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=custom_generator) \n",
    "\n",
    "\n",
    "\n",
    "def generate_summary(sentiment, decision,companyName,history):\n",
    " sentiment_text=\"\"\n",
    " if decision == \"Invest\":\n",
    "        if sentiment[\"average\"] > 0.5:\n",
    "            sentiment_text = f\"The overall sentiment is positive, indicating a potentially favorable investment climate.\"\n",
    "        else:\n",
    "            sentiment_text = f\"While the sentiment leans slightly positive, further analysis is recommended to confirm the investment's viability.\"\n",
    " else:\n",
    "     sentiment_text = f\"Sentiment analysis indicates to be cautious about {companyName}\"\n",
    " try:\n",
    "  with open('config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    api_keyOpenAI = config['openAI']\n",
    " except:\n",
    "  print(\"Unable to access stock data\")\n",
    " llm = OpenAI(temperature=0.7, api_key=api_keyOpenAI) \n",
    "\n",
    "\n",
    " prompt_template = PromptTemplate(\n",
    "    input_variables=[\"negative\", \"neutral\", \"positive\", \"average\", \"decision\",\"companyName\",\"history\",\"sentimenttext\"],\n",
    "    template=(\n",
    "        \"The sentiment analysis of recent news articles about the company reveals:\\n\"\n",
    "        \"  * Negative sentiment: {negative:.2f}\\n\"\n",
    "        \"  * Neutral sentiment: {neutral:.2f}\\n\"\n",
    "        \"  * Positive sentiment: {positive:.2f}\\n\"\n",
    "        \"  * compound sentiment: {average:.2f}\\n\"\n",
    "        \"Based on this analysis, the investment decision is: {decision}.\\n The compound sentiment of {companyName} is {average:2f} I analysed that {sentimenttext} predict its stock performance based on the history provided ({history}) and above provided sentiment analysis\"\n",
    "    )\n",
    ")\n",
    " \n",
    " chain = LLMChain(prompt=prompt_template, llm=llm)\n",
    " generated_text = chain.run({\n",
    "    \"negative\": sentiment['negative'],\n",
    "    \"neutral\": sentiment['neutral'],\n",
    "    \"positive\": sentiment['positive'],\n",
    "    \"average\": sentiment['average'],\n",
    "    \"decision\": decision,\n",
    "    \"companyName\": companyName,\n",
    "    \"history\": history,\n",
    "    \"sentimenttext\":sentiment_text\n",
    "})\n",
    " return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user voice input should be like \"Recommend me a stock on google\" and it will work with the organizations set up in provided company-ticker.csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please reach out to me if any errors due to configuration of apikeys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for your investment query...\n",
      "You said: recommend me a stock on Tesla\n",
      "Tesla\n",
      "TSLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apikey of news:8241d031a740409ebfbbddb45d0bcacb\n",
      "https://newsapi.org/v2/everything?q=Tesla&domains=bloomberg.com,cnbc.com,financialpost.com,financialexpress.com,marketwatch.com,reuters.com,wsj.com,yahoo.com&sortBy=publishedAt&apiKey=8241d031a740409ebfbbddb45d0bcacb\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from playsound import playsound\n",
    "from gtts import gTTS\n",
    "\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        #st.write(\"Listening for your investment query...\")\n",
    "        print(\"Listening for your investment query...\")\n",
    "        audio = recognizer.listen(source)      \n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(\"You said:\", text)\n",
    "            #st.write(\"You said:\", text)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition could not understand audio\")\n",
    "            #st.write(\"Google Speech Recognition could not understand audio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results; {e}\")\n",
    "            #st.write(f\"Could not request results; {e}\")\n",
    "    return \"\"\n",
    "\n",
    "speech_text = recognize_speech()\n",
    "if speech_text:\n",
    "        company_name = extract_companyName(speech_text)\n",
    "        if company_name is not None:\n",
    "            print(company_name)\n",
    "            ticker = extract_tickerFromExcel(company_name)\n",
    "            print(ticker)\n",
    "            if ticker:\n",
    "                real_time_data = fetch_realtime_data(ticker)\n",
    "                if real_time_data.empty:\n",
    "                    print(f\"No real-time data found for ticker {ticker}.\")\n",
    "\n",
    "                current_price = real_time_data['Close'].values[-1]\n",
    "                \n",
    "                news_articles = fetch_news(extract_companyName(speech_text))\n",
    "                if not news_articles:\n",
    "                    print(f\"No news articles found for {company_name}.\")\n",
    "                sentiment = analyze_sentiment(news_articles)\n",
    "                decision = predict_stock_movement(sentiment)\n",
    "                print(f\"ticker: {ticker}\")\n",
    "                print(f\"Current Price: {current_price}\")\n",
    "                symbol = ticker \n",
    "                stockHistory = fetch_daily_stock_data(symbol)\n",
    "                if stockHistory is not None:\n",
    "                    print(\"Daily Data:\")\n",
    "                    print(stockHistory.tail(10))  \n",
    "                print(f\"Sentiment Analysis: {sentiment}\")\n",
    "                print(f\"Decision: {decision}\")\n",
    "                summary = generate_summary(sentiment, decision,extract_companyName(speech_text),stockHistory.tail(10))\n",
    "                print(\"\\nSummary:\")\n",
    "                if summary is not None:\n",
    "                    for line in summary.split('.'):\n",
    "                            if line.strip(): \n",
    "                                print(line.strip() + '.')\n",
    "                    #text_to_speech(summary,f\"summary_{company_name}.mp3\")\n",
    "                else:\n",
    "                 summary = \"Sorry could not fetch recommendation. please try again later\" \n",
    "                 \n",
    "            else:\n",
    "              print(\"Could not extract stock ticker from your query.\")\n",
    "        else:\n",
    "            print(\"Provide suitable inputs related to recommending a stock / organization data not available with us.\")\n",
    "else:\n",
    "        print(\"No input detected.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
